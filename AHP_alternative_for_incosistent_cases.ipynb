{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNS2gGlY6pExap9fu0XRg9r",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vaclavkratochvil/Consistency-independent-Multiple-criteria-Decision-Technique/blob/main/AHP_alternative_for_incosistent_cases.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Supplementary Material for **Multi-Criteria Decision Making Beyond Consistency: An Alternative to AHP for Real-World Industrial Problems**\n",
        "\n",
        "This Jupyter Notebook contains the supplementary material for the paper *Multi-Criteria Decision Making Beyond Consistency: An Alternative to AHP for Real-World Industrial Problems* by *Silvia Carpitella*, *Václav Kratochvíl*, and *Miroslav Pištěk* submitted for publication in 2024. This document includes the source code and several examples demonstrating the usage and results discussed in the paper.\n",
        "\n",
        "\n",
        "**!! To run the code, open it in [Google Colab](https://colab.research.google.com/github/vaclavkratochvil/AHP/blob/main/AHP_alternative_for_incosistent_cases.ipynb) !!**\n",
        "\n",
        "The paper generalizes concepts from the recent publication:\n",
        ">  Carpitella Silvia, Inuiguchi Masahiro, Kratochvíl Václav, Pištěk Miroslav :  Multi-criteria decision analysis without consistency in pairwise comparisons , Computers & Industrial Engineering vol.168, 2022. [10.1016/j.cie.2022.108089](https://doi.org/10.1016/j.cie.2022.108089)\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "-nInTIDedvmI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Aggregated Preference Matrix\n",
        "The aggregated preference matrix is a composite matrix derived from multiple pairwise comparison matrices (PCMs) and a vector of weights that signify the relative importance of each PCM. Each reciprocal PCM $R^{(i)}$ is weighted by $w_i$​ from the weight vector $w$. The aggregated preference matrix is computed using the element-wise geometric mean of the weighted PCMs, ensuring that the results remains reciprocal. This process is crucial for combining evaluations across different criteria or experts into a single, coherent PCM for decision-making. For a precise definition, see equation (3) in refered paper."
      ],
      "metadata": {
        "id": "FrbIskMVfBj0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def aggregated_preference_matrix(R_list, w):\n",
        "    \"\"\"\n",
        "    Compute the aggregated preference matrix using element-wise weighted geometric mean.\n",
        "\n",
        "    Parameters:\n",
        "    R_list (list of np.ndarray): List of pairwise comparison matrices as NumPy arrays.\n",
        "    w (np.ndarray): Weight vector.\n",
        "\n",
        "    Returns:\n",
        "    np.ndarray: Aggregated preference matrix.\n",
        "    \"\"\"\n",
        "    # Ensure the number of matrices matches the number of weights\n",
        "    if len(R_list) != len(w):\n",
        "        raise ValueError(\"The number of matrices and weights must be the same.\")\n",
        "\n",
        "    # Compute the element-wise weighted geometric mean\n",
        "    weighted_geom_mean = np.ones_like(R_list[0])\n",
        "    for matrix, weight in zip(R_list, w):\n",
        "        weighted_geom_mean *= np.power(matrix, weight)\n",
        "\n",
        "    return weighted_geom_mean\n",
        "\n",
        "# Define a helper function to print matrices or vectors with row and column names\n",
        "def print_named_matrix_or_vector(matrix_or_vector, row_names, col_names=None):\n",
        "    if col_names is None:  # It's a vector\n",
        "        # Determine the maximum length of the names for proper alignment\n",
        "        max_name_length = max(len(name) for name in row_names)\n",
        "\n",
        "        # Print the vector\n",
        "        for row_name, val in zip(row_names, matrix_or_vector):\n",
        "            print(f\"{row_name:>{max_name_length}}: {val:.4f}\")\n",
        "    else:  # It's a matrix\n",
        "        # Determine the maximum length of the names for proper alignment\n",
        "        max_name_length = max(max(len(name) for name in row_names), max(len(name) for name in col_names))\n",
        "\n",
        "        # Print the column headers\n",
        "        print(\" \" * (max_name_length + 1), end=\"\")\n",
        "        for name in col_names:\n",
        "            print(f\"{name:>{max_name_length}}\", end=\" \")\n",
        "        print()\n",
        "\n",
        "        # Print each row with its name\n",
        "        for row_name, row in zip(row_names, matrix_or_vector):\n",
        "            print(f\"{row_name:>{max_name_length}}\", end=\" \")\n",
        "            for val in row:\n",
        "                print(f\"{val:>{max_name_length}.4f}\", end=\" \")\n",
        "            print()\n",
        "        print()\n"
      ],
      "metadata": {
        "id": "YGMiO-yPf2xs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The canonical weight vector\n",
        "The canonical weight vector is determined through a process that begins with a reciprocal pairwise comparison matrix (PCM). By taking the element-wise logarithm of the PCM, a skew-symmetric matrix is obtained. This matrix allows the formulation of a system of linear inequalities that identifies all maximal preferred elements based on the Subjective Stochastic Dominance (SSB) representation. To address any potential non-uniqueness among these elements, the optimal distribution of preference is defined as the unique maximal preferred element that maximizes entropy. This optimal distribution represents the most balanced and unbiased allocation of preferences.\n",
        "\n",
        "The canonical weight vector is then derived by taking the normalized inverse of the vector resulting from multiplying the transpose of the reciprocal PCM by the optimal distribution of preference. This vector reflects the relative scores of individual alternatives, ensuring a coherent and consistent representation of preferences. For a consistent PCM, the canonical weight vector aligns with the weight vector used in the Analytic Hierarchy Process (AHP). This approach ensures that the derived weight vector accurately represents the underlying preferences and priorities, even in the presence of inconsistencies within the PCM.\n",
        "\n",
        "The functions are based on equations (4), (5), and (6) in the referenced paper."
      ],
      "metadata": {
        "id": "1UENOKgqgdn-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f5XNazWPUQ3o"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from scipy.optimize import minimize\n",
        "\n",
        "def find_max_entropy_SSB_max(X):\n",
        "    \"\"\"\n",
        "    It identifies the optimal distribution of preference within a given pairwise\n",
        "    comparison matrix X. The function leverages the property that the element-wise\n",
        "    logarithm of a PCM results in a skew-symmetric matrix, which allows the\n",
        "    formulation of a system of linear inequalities to determine all maximal\n",
        "    preferred elements in the sense of SSB (Subjective Stochastic Dominance) representation.\n",
        "\n",
        "    To address potential non-uniqueness among these maximal preferred elements,\n",
        "    the function defines the optimal distribution of preference as the unique\n",
        "    maximal preferred element that maximizes entropy.\n",
        "\n",
        "    Parameters:\n",
        "    X (numpy.ndarray): Pairwise comparison matrix with preferences\n",
        "\n",
        "    Returns:\n",
        "    numpy.ndarray: The optimal distribution of preference that maximizes entropy.\n",
        "    \"\"\"\n",
        "\n",
        "    # Shannon entropy as the objective function for minimization\n",
        "    def shannon_entropy_point(point):\n",
        "        probabilities = point / np.sum(point)\n",
        "        entropy = -np.sum(probabilities * np.log(probabilities + 1e-9))  # Adding a small number to avoid log(0)\n",
        "        return entropy\n",
        "\n",
        "    # Automatically generate an initial point using the Dirichlet distribution\n",
        "    def generate_initial_point(dimensions):\n",
        "        return np.random.dirichlet(np.ones(dimensions))\n",
        "\n",
        "    # Determine the number of dimensions from matrix X\n",
        "    num_dimensions = X.shape[1]\n",
        "\n",
        "    # Generate a valid initial point\n",
        "    initial_point = generate_initial_point(num_dimensions)\n",
        "\n",
        "    # Constraints for SSB maximal element\n",
        "    constraints = [\n",
        "        {'type': 'ineq', 'fun': lambda m: -np.dot(X, m)},  # Xm <= 0\n",
        "        {'type': 'eq', 'fun': lambda m: np.sum(m) - 1},    # m1 + m2 + m3 + ... = 1\n",
        "        {'type': 'ineq', 'fun': lambda m: m}               # m >= 0 (non-negative)\n",
        "    ]\n",
        "\n",
        "    # Find the maximum element (note the negative sign to maximize entropy)\n",
        "    result = minimize(lambda m: -shannon_entropy_point(m), initial_point, constraints=constraints, bounds=[(0, None)] * num_dimensions)\n",
        "\n",
        "    # Result\n",
        "    return result.x\n",
        "\n",
        "def kappa(R):\n",
        "    \"\"\"\n",
        "    Compute the canonical weight vector \\kappa(R) for reciprocal matrix R.\n",
        "\n",
        "    Parameters:\n",
        "    R (numpy.ndarray): Input reciprocal matrix.\n",
        "\n",
        "    Returns:\n",
        "    numpy.ndarray: weight vector of preferences.\n",
        "    \"\"\"\n",
        "    # Step 1: Create SSB matrix X\n",
        "    X = np.log(R)\n",
        "\n",
        "    # Step 2: Find the minimum entropy point m_tilde\n",
        "    m_tilde = find_max_entropy_SSB_max(X)\n",
        "\n",
        "    # Step 3: Calculate vector pi\n",
        "    pi = np.dot(R.T, m_tilde)\n",
        "\n",
        "    # Step 4: Normalize vector 1/pi\n",
        "    inv_pi = 1 / pi\n",
        "    normalized_inv_pi = inv_pi / np.sum(inv_pi)\n",
        "\n",
        "    return normalized_inv_pi\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "Ce5irN1Vgb33"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Consistency independent Decision Technique\n",
        "Given a multi-criteria decision-making problem encoded in AHP-like format. I.e Matrix $A$ represents the pairwise comparison matrix for the criteria relative to the goal. Each matrix in the list $B$ represents the pairwise comparison of alternatives with respect to each criterion.\n",
        "\n",
        "Our consistency independent technique is the following:\n",
        "1. Given reciprocal matrix $A$ we calculate the cannonical weight vector $\\kappa(A)$\n",
        "2. The obtained vector is used as a weight to aggregate matrices $B$ using the (weighted) geometric mean, thus obtaining aggregated preference matrix $B^{\\kappa(A)}$\n",
        "3. Such a matrix is again reciprocal, we may evaluate the vector of final weights $z_{CI}$ as $κ(B^{\\kappa(A)})$\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "pSmUw9QOdkwI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Leader example\n",
        "To demonstrate the typical problem, let's consider a decision-making scenario by [Wikipedia](https://w.wiki/AUJZ) involving three alternatives and four criteria. This can be exemplified using a scenario called \"Tom, Dick, and Harry,\" which is based on a real-world situation of selecting a new leader for a company facing the retirement of its founder. In this example, there are three potential candidates for the leadership role - **Tom**, **Dick**, and **Harry** - and they are assessed based on four different criteria: **Age**, **Charisma**, **Education**, and **Experience**. The problem involves comparing these criteria in pairs and recording the preferences in a matrix form.\n",
        "\n",
        "The example is discussed in **Section 4.3.1** in the referred paper.\n",
        "\n",
        "First, we will define the pairwise comparison matrices for Experience, Education, Charisma, and Age, as well as the criteria comparison matrix."
      ],
      "metadata": {
        "id": "4u-GQgxRmGj0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Leader names\n",
        "leader_names = [\"Tom\", \"Dick\", \"Harry\"]\n",
        "\n",
        "# Pairwise comparison matrix for Experience\n",
        "experience = np.array([\n",
        "    [1, 1/4, 4],\n",
        "    [4, 1, 9],\n",
        "    [1/4, 1/9, 1]\n",
        "])\n",
        "print(\"Experience:\")\n",
        "print_named_matrix_or_vector(experience, leader_names, leader_names)\n",
        "\n",
        "# Pairwise comparison matrix for Education\n",
        "education = np.array([\n",
        "    [1, 3, 1/5],\n",
        "    [1/3, 1, 1/7],\n",
        "    [5, 7, 1]\n",
        "])\n",
        "print(\"Education:\")\n",
        "print_named_matrix_or_vector(education, leader_names, leader_names)\n",
        "\n",
        "# Pairwise comparison matrix for Charisma\n",
        "charisma = np.array([\n",
        "    [1, 5, 9],\n",
        "    [1/5, 1, 4],\n",
        "    [1/9, 1/4, 1]\n",
        "])\n",
        "print(\"Charisma:\")\n",
        "print_named_matrix_or_vector(charisma, leader_names, leader_names)\n",
        "\n",
        "# Pairwise comparison matrix for Age\n",
        "age = np.array([\n",
        "    [1, 1/3, 5],\n",
        "    [3, 1, 9],\n",
        "    [1/5, 1/9, 1]\n",
        "])\n",
        "print(\"Age:\")\n",
        "print_named_matrix_or_vector(age, leader_names, leader_names)\n",
        "\n",
        "# List of pairwise comparison matrices\n",
        "B_list = [experience, education, charisma, age]\n",
        "\n",
        "# Criteria comparison matrix\n",
        "criteria_names = [\"Experience\", \"Education\", \"Charisma\", \"Age\"]\n",
        "criteria = np.array([\n",
        "    [1, 4, 3, 7],\n",
        "    [1/4, 1, 1/3, 3],\n",
        "    [1/3, 3, 1, 5],\n",
        "    [1/7, 1/3, 1/5, 1]\n",
        "])\n",
        "print(\"Criteria:\")\n",
        "print_named_matrix_or_vector(criteria, criteria_names, criteria_names)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oUzz0FJUmeUv",
        "outputId": "6a9a18ee-d310-4b7e-99af-19456f29aa50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Experience:\n",
            "        Tom  Dick Harry \n",
            "  Tom 1.0000 0.2500 4.0000 \n",
            " Dick 4.0000 1.0000 9.0000 \n",
            "Harry 0.2500 0.1111 1.0000 \n",
            "\n",
            "Education:\n",
            "        Tom  Dick Harry \n",
            "  Tom 1.0000 3.0000 0.2000 \n",
            " Dick 0.3333 1.0000 0.1429 \n",
            "Harry 5.0000 7.0000 1.0000 \n",
            "\n",
            "Charisma:\n",
            "        Tom  Dick Harry \n",
            "  Tom 1.0000 5.0000 9.0000 \n",
            " Dick 0.2000 1.0000 4.0000 \n",
            "Harry 0.1111 0.2500 1.0000 \n",
            "\n",
            "Age:\n",
            "        Tom  Dick Harry \n",
            "  Tom 1.0000 0.3333 5.0000 \n",
            " Dick 3.0000 1.0000 9.0000 \n",
            "Harry 0.2000 0.1111 1.0000 \n",
            "\n",
            "Criteria:\n",
            "           Experience  Education   Charisma        Age \n",
            "Experience     1.0000     4.0000     3.0000     7.0000 \n",
            " Education     0.2500     1.0000     0.3333     3.0000 \n",
            "  Charisma     0.3333     3.0000     1.0000     5.0000 \n",
            "       Age     0.1429     0.3333     0.2000     1.0000 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compute the result using our technique\n"
      ],
      "metadata": {
        "id": "M5KYUSKKnwoe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute the cannonical weight vector for the criteria matrix using the kappa function\n",
        "criteria_weights = kappa(criteria)\n",
        "\n",
        "# Compute the aggregated preference matrix\n",
        "aggregated_matrix = aggregated_preference_matrix(B_list, criteria_weights)\n",
        "\n",
        "print(\"Aggregated Preference Matrix:\")\n",
        "print_named_matrix_or_vector(aggregated_matrix, leader_names, leader_names)\n",
        "\n",
        "# Compute the final weights using the kappa function\n",
        "final_weights = kappa(aggregated_matrix)\n",
        "\n",
        "print(\"Final Weights:\")\n",
        "print_named_matrix_or_vector(final_weights, leader_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "74zLnXJon70v",
        "outputId": "e8331ab0-94f2-445b-9e5e-f9f61e8d648a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Aggregated Preference Matrix:\n",
            "        Tom  Dick Harry \n",
            "  Tom 1.0000 0.6543 3.0879 \n",
            " Dick 1.5282 1.0000 4.2232 \n",
            "Harry 0.3238 0.2368 1.0000 \n",
            "\n",
            "Final Weights:\n",
            "  Tom: 0.3460\n",
            " Dick: 0.5288\n",
            "Harry: 0.1252\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Car example\n",
        "The Jones family is in the market for a new vehicle. They have identified several criteria that are important to them in making their decision. These criteria include cost, safety, style, and capacity. Each criterion has specific subcriteria that further define the family's preferences.\n",
        "\n",
        "**Criteria and Subcriteria**\n",
        "* Cost:\n",
        "  * Purchase Price: The initial cost of buying the car.\n",
        "  * Maintenance Cost: The expected cost of maintaining the car.\n",
        "  * Fuel Cost: The fuel efficiency and expected fuel expenses.\n",
        "  * Resale Value: The estimated resale value of the car.\n",
        "\n",
        "* Safety:\n",
        "  The overall safety ratings and features of the car.\n",
        "\n",
        "* Style:\n",
        "  The aesthetic appeal and design of the car.\n",
        "\n",
        "* Capacity:\n",
        "  * Passenger Capacity: The number of passengers the car can comfortably accommodate.\n",
        "* Cargo Capacity: The amount of cargo space available in the car.\n",
        "\n",
        "**Alternatives:**\n",
        "The family is considering the following car models:\n",
        " Accord Hybrid Sedan, Accord Sedan, CR-V SUV, Element SUV, Odyssey Minivan, Pilot SUV\n",
        "\n",
        "See **Section 4.3.2** in the referred paper.\n"
      ],
      "metadata": {
        "id": "R-dagHP4YsZr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " Cost subcriteria:"
      ],
      "metadata": {
        "id": "ziuhiVLO-BWA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Car names\n",
        "car_names = [\"Accord Hybrid\", \"Accord Sedan\", \"CR-V\", \"Element\", \"Odyssey\", \"Pilot\"]\n",
        "\n",
        "# Purchase Price Matrix\n",
        "purchase_price = np.array([\n",
        "    [1, 1/9, 1/9, 1/9, 1/7, 1],\n",
        "    [9, 1, 1, 1/2, 5, 9],\n",
        "    [9, 1, 1, 1/2, 5, 9],\n",
        "    [9, 2, 2, 1, 6, 9],\n",
        "    [7, 1/5, 1/5, 1/6, 1, 7],\n",
        "    [1, 1/9, 1/9, 1/9, 1/7, 1]\n",
        "])\n",
        "\n",
        "# Maintenance Cost Matrix\n",
        "maintenance_cost = np.array([\n",
        "    [1, 2/3, 4, 4, 5, 4],\n",
        "    [3/2, 1, 4, 4, 5, 4],\n",
        "    [1/4, 1/4, 1, 1, 3, 1],\n",
        "    [1/4, 1/4, 1, 1, 2, 5/6],\n",
        "    [1/5, 1/5, 1/3, 1/2, 1, 1],\n",
        "    [1/4, 1/4, 1, 1.2, 1, 1]\n",
        "])\n",
        "\n",
        "# Resale Value Matrix\n",
        "resale_value = np.array([\n",
        "    [1, 1/3, 1/5, 1, 1, 2],\n",
        "    [3, 1, 1/2, 2, 2, 4],\n",
        "    [5, 2, 1, 4, 4, 6],\n",
        "    [1, 2, 4, 1, 1, 2],\n",
        "    [1, 2, 4, 1, 1, 2],\n",
        "    [2, 4, 6, 2, 2, 1]\n",
        "])\n",
        "\n",
        "# Fuel Cost Matrix\n",
        "fuel_cost = np.array([\n",
        "    [1, 113/100, 13/10, 14/10, 135/100, 159/100],\n",
        "    [100/113, 1, 23/20, 31/25, 119/100, 141/100],\n",
        "    [10/13, 20/23, 1, 27/25, 26/25, 123/100],\n",
        "    [5/7, 25/31, 25/27, 1, 25/26, 57/50],\n",
        "    [20/27, 100/119, 25/26, 26/25, 1, 59/50],\n",
        "    [100/159, 100/141, 100/123, 50/57, 50/59, 1]\n",
        "])\n",
        "\n",
        "# Cost Criteria Matrix\n",
        "cost_criteria = np.array([\n",
        "    [1, 2, 1/2, 2],\n",
        "    [1/2, 1, 1/5, 1/2],\n",
        "    [2, 5, 1, 3],\n",
        "    [1/2, 2, 1/3, 1]\n",
        "])"
      ],
      "metadata": {
        "id": "-PPAptGv-E50"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Capacity subcriteria:"
      ],
      "metadata": {
        "id": "fAVzG6gU-N_h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Passenger Capacity Matrix\n",
        "passenger_capacity = np.array([\n",
        "    [1, 1, 5, 9, 6, 7],\n",
        "    [1, 1, 5, 9, 6, 7],\n",
        "    [1/5, 1/5, 1, 7, 5, 6],\n",
        "    [1/9, 1/9, 1/7, 1, 1/5, 1/3],\n",
        "    [1/6, 1/6, 1/5, 5, 1, 3],\n",
        "    [1/7, 1/7, 1/6, 1/3, 1/3, 1]\n",
        "])\n",
        "\n",
        "# Cargo Capacity Matrix\n",
        "cargo_capacity = np.array([\n",
        "    [1, 1, 1/2, 1/2, 1/3, 1/2],\n",
        "    [1, 1, 1/2, 1/2, 1/3, 1/2],\n",
        "    [2, 2, 1, 1, 1/2, 1],\n",
        "    [2, 2, 1, 1, 1/2, 1],\n",
        "    [3, 3, 2, 2, 1, 2],\n",
        "    [2, 2, 1, 1, 1/2, 1]\n",
        "])\n",
        "\n",
        "# Capacity Criteria Matrix\n",
        "capacity_criteria = np.array([\n",
        "    [1, 1/5],\n",
        "    [5, 1]\n",
        "])"
      ],
      "metadata": {
        "id": "WI1HNLEv-TG-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Other Criteria Matrices:"
      ],
      "metadata": {
        "id": "PYvr8xC1-ZlH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Safety Matrix\n",
        "safety = np.array([\n",
        "    [1, 1, 7, 9, 1/3, 5],\n",
        "    [1, 1, 7, 9, 1/3, 5],\n",
        "    [1/7, 1/7, 1, 2, 1/8, 1/2],\n",
        "    [1/9, 1/9, 1/2, 1, 1/9, 1/9],\n",
        "    [3, 3, 8, 9, 1, 8],\n",
        "    [1/5, 1/5, 1/2, 1, 1/8, 1]\n",
        "])\n",
        "\n",
        "# Style Matrix\n",
        "style = np.array([\n",
        "    [1, 1, 5, 9, 6, 7],\n",
        "    [1, 1, 5, 9, 6, 7],\n",
        "    [1/5, 1/5, 1, 7, 5, 6],\n",
        "    [1/9, 1/9, 1/7, 1, 1/5, 1/3],\n",
        "    [1/6, 1/6, 1/5, 5, 1, 3],\n",
        "    [1/7, 1/7, 1/6, 1/3, 1/3, 1]\n",
        "])\n",
        "\n",
        "# Criteria Comparison Matrix\n",
        "# in the following ordering: capacity, cost, safety, style\n",
        "criteria = np.array([\n",
        "    [1, 1/3, 1, 7],\n",
        "    [3, 1, 3, 7],\n",
        "    [1, 1/3, 1, 9],\n",
        "    [1/7, 1/7, 1/9, 1]\n",
        "])"
      ],
      "metadata": {
        "id": "4DgD-GSX-d2L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step-by-Step Solution:\n",
        "\n",
        " * **Subproblem 1: Cost Sub-Criteria Aggregation**\n",
        "  Compute the aggregated preference matrix `cost` for the cost sub-criteria (Purchase Price, Maintenance Cost, Resale Value, Fuel Cost).\n",
        "\n",
        "* **Subproblem 2: Capacity Sub-Criteria Aggregation**\n",
        "  Compute the aggregated preference matrix `capacity` for the capacity sub-criteria (Passenger Capacity, Cargo Capacity).\n",
        "\n",
        "* **Aggregate Main Criteria Matrices**\n",
        "  Use the aggregated preference matrices from the subproblems as inputs for the main criteria (`cost, capacity, safety, style`)."
      ],
      "metadata": {
        "id": "lOnBjXVW-iSm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "### Subproblem 1 ###\n",
        "# compute the cannonical weight vector\n",
        "weights = kappa(cost_criteria)\n",
        "B_cost = [purchase_price, maintenance_cost, resale_value, fuel_cost]\n",
        "cost = aggregated_preference_matrix(B_cost, weights)\n",
        "\n",
        "print(\"Cost subproblem - aggregated matrix:\")\n",
        "print_named_matrix_or_vector(cost, car_names, car_names)\n",
        "\n",
        "### Subproblem 2 ###\n",
        "# compute the cannonical weight vector\n",
        "weights = kappa(capacity_criteria)\n",
        "B_capacity = [passenger_capacity, cargo_capacity]\n",
        "capacity = aggregated_preference_matrix(B_capacity, weights)\n",
        "\n",
        "print(\"Capacity subproblem - aggregated matrix:\")\n",
        "print_named_matrix_or_vector(capacity, car_names, car_names)\n",
        "\n",
        "### Final solution ###\n",
        "# compute the cannonical weight vector\n",
        "weights = kappa(criteria)\n",
        "B = [capacity, cost, safety, style]\n",
        "\n",
        "# aggregate list of pairwise comparison matrices for capacity, cost, safety, style\n",
        "aggregated_matrix = aggregated_preference_matrix(B, weights)\n",
        "\n",
        "# evaluate the final vector\n",
        "z_CI = kappa(aggregated_matrix)\n",
        "print(\"Final results z_CI:\")\n",
        "print_named_matrix_or_vector(z_CI, car_names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WaNcKbimapUH",
        "outputId": "eb69c7a0-d744-44d5-905d-553a4e971482"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cost subproblem - aggregated matrix:\n",
            "              Accord Hybrid  Accord Sedan          CR-V       Element       Odyssey         Pilot \n",
            "Accord Hybrid        1.0000        0.3327        0.3159        0.7055        0.7626        1.7389 \n",
            " Accord Sedan        3.0055        1.0000        0.8339        1.4079        2.5180        4.1155 \n",
            "         CR-V        3.1660        1.1992        1.0000        1.6887        3.2938        4.2863 \n",
            "      Element        1.4173        1.4046        2.3155        1.0000        1.6526        2.4224 \n",
            "      Odyssey        1.3113        0.7853        1.1871        0.6051        1.0000        2.3315 \n",
            "        Pilot        1.1371        0.9501        1.3593        0.8163        0.8481        1.0000 \n",
            "\n",
            "Capacity subproblem - aggregated matrix:\n",
            "              Accord Hybrid  Accord Sedan          CR-V       Element       Odyssey         Pilot \n",
            "Accord Hybrid        1.0000        1.0000        0.7339        0.8094        0.5396        0.7762 \n",
            " Accord Sedan        1.0000        1.0000        0.7339        0.8094        0.5396        0.7762 \n",
            "         CR-V        1.3626        1.3626        1.0000        1.3831        0.7339        1.3480 \n",
            "      Element        1.2354        1.2354        0.7230        1.0000        0.4292        0.8327 \n",
            "      Odyssey        1.8531        1.8531        1.3626        2.3300        1.0000        2.1398 \n",
            "        Pilot        1.2883        1.2883        0.7418        0.8327        0.4673        1.0000 \n",
            "\n",
            "Final results z_CI:\n",
            "Accord Hybrid: 0.1484\n",
            " Accord Sedan: 0.2578\n",
            "         CR-V: 0.1842\n",
            "      Element: 0.1323\n",
            "      Odyssey: 0.1963\n",
            "        Pilot: 0.0810\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Industrial application\n",
        "A textile manufacturing company in Italy seeks to optimize its supplier selection process using the Analytic Hierarchy Process (AHP) methodology to choose the best data analytics tool. The company's operations *span product development, manufacturing, sales, marketing, and overall management*. Key criteria for tool selection include *quality assurance, cost efficiency, delivery reliability, supplier reputation, and environmental impact*. Eight pre-screened tools are evaluated against these criteria. A decision-making group of three stakeholders (*supply chain analyst, market trend analyst, and sustainability auditor*) provides input, with their evaluations aggregated using AHP to ensure systematic, data-driven decision-making. Implementing the chosen tool involves significant costs in acquisition, infrastructure, training, and integration.\n",
        "\n",
        "More information can be found in **Section 5** of the referred paper."
      ],
      "metadata": {
        "id": "p14p68wDk5S2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definition:"
      ],
      "metadata": {
        "id": "RvG842JXFMAL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Define criteria names\n",
        "cNames = [\"C1\", \"C2\", \"C3\", \"C4\", \"C5\"]\n",
        "\n",
        "# Define the matrices DM1, DM2, DM3\n",
        "DM1 = np.array([\n",
        "    [1, 3, 2, 4, 4],\n",
        "    [1/3, 1, 4, 5, 4],\n",
        "    [1/2, 1/4, 1, 1/6, 5],\n",
        "    [1/4, 1/5, 6, 1, 5],\n",
        "    [1/4, 1/4, 1/5, 1/5, 1]\n",
        "])\n",
        "\n",
        "DM2 = np.array([\n",
        "    [1, 3, 3, 4, 1],\n",
        "    [1/3, 1, 1/5, 1/4, 1/2],\n",
        "    [1/3, 5, 1, 2, 3],\n",
        "    [1/4, 4, 1/2, 1, 4],\n",
        "    [1, 2, 1/3, 1/4, 1]\n",
        "])\n",
        "\n",
        "DM3 = np.array([\n",
        "    [1, 6, 6, 7, 1/8],\n",
        "    [1/6, 1, 1/5, 1/4, 1/2],\n",
        "    [1/6, 5, 1, 5, 1/3],\n",
        "    [1/7, 4, 1/5, 1, 1/9],\n",
        "    [8, 2, 3, 9, 1]\n",
        "])\n",
        "\n",
        "# Compute the geometric mean of the input matrices\n",
        "DM = (DM1 * DM2 * DM3) ** (1/3)\n",
        "print(\"Aggregated criteria matrix:\" )\n",
        "print_named_matrix_or_vector(DM, cNames, cNames)\n",
        "\n",
        "# Define alternative names\n",
        "bNames = [\"AT1\", \"AT2\", \"AT3\", \"AT4\", \"AT5\", \"AT6\", \"AT7\", \"AT8\"]\n",
        "\n",
        "# Define the matrices B1, B2, B3, B4, B5\n",
        "B1 = np.array([\n",
        "    [1, 1/2, 1/8, 1/7, 2, 1/4, 1/6, 1/2],\n",
        "    [2, 1, 1/9, 1/6, 3, 1/2, 1/2, 1/2],\n",
        "    [8, 9, 1, 2, 9, 4, 3, 5],\n",
        "    [7, 6, 1/2, 1, 8, 3, 2, 6],\n",
        "    [1/2, 1/3, 1/9, 1/8, 1, 1/3, 1/6, 1/3],\n",
        "    [4, 2, 1/4, 1/3, 3, 1, 2, 2],\n",
        "    [6, 2, 1/3, 1/2, 6, 1/2, 1, 3],\n",
        "    [2, 2, 1/5, 1/6, 3, 1/2, 1/3, 1]\n",
        "])\n",
        "\n",
        "B2 = np.array([\n",
        "    [1, 1/2, 1/8, 1/7, 2, 1/4, 1/2, 1/2],\n",
        "    [2, 1, 1/9, 1/6, 3, 1/2, 1/2, 1/2],\n",
        "    [8, 9, 1, 2, 9, 4, 3, 5],\n",
        "    [7, 6, 1/2, 1, 8, 3, 2, 2],\n",
        "    [1/2, 1/3, 1/9, 1/8, 1, 1/3, 1/6, 1/3],\n",
        "    [4, 2, 1/4, 1/3, 3, 1, 2, 2],\n",
        "    [2, 2, 1/3, 1/2, 6, 1/2, 1, 1/6],\n",
        "    [2, 2, 1/5, 1/2, 3, 1/2, 6, 1]\n",
        "])\n",
        "\n",
        "B3 = np.array([\n",
        "    [1, 1/2, 1/8, 1/7, 2, 1/4, 1/2, 1/2],\n",
        "    [2, 1, 1/9, 1/6, 3, 1/2, 1/2, 1/2],\n",
        "    [8, 9, 1, 2, 9, 4, 3, 5],\n",
        "    [7, 6, 1/2, 1, 8, 3, 2, 2],\n",
        "    [1/2, 1/3, 1/9, 1/8, 1, 1/3, 1/6, 1/3],\n",
        "    [4, 2, 1/4, 1/3, 3, 1, 2, 2],\n",
        "    [2, 2, 1/3, 1/2, 6, 1/2, 1, 1/6],\n",
        "    [2, 2, 1/5, 1/2, 3, 1/2, 6, 1]\n",
        "])\n",
        "\n",
        "B4 = np.array([\n",
        "    [1, 1/2, 1/8, 1/7, 1/8, 1/4, 1/2, 1/2],\n",
        "    [2, 1, 1/4, 1/6, 1/3, 2, 2, 2],\n",
        "    [8, 4, 1, 2, 1/2, 4, 3, 5],\n",
        "    [7, 6, 1/2, 1, 1/3, 3, 2, 2],\n",
        "    [8, 3, 2, 3, 1, 6, 7, 8],\n",
        "    [4, 1/2, 1/4, 1/3, 1/6, 1, 2, 2],\n",
        "    [2, 1/2, 1/3, 1/2, 1/7, 1/2, 1, 1/6],\n",
        "    [2, 1/2, 1/5, 1/2, 1/8, 1/2, 6, 1]\n",
        "])\n",
        "\n",
        "B5 = np.array([\n",
        "    [1, 1/2, 1/8, 1/7, 2, 1/4, 1/2, 1/2],\n",
        "    [2, 1, 1/4, 1/2, 5, 2, 2, 3],\n",
        "    [8, 4, 1, 2, 8, 4, 3, 5],\n",
        "    [7, 2, 1/2, 1, 7, 3, 2, 2],\n",
        "    [1/2, 1/5, 1/8, 1/7, 1, 1/6, 1/7, 1/8],\n",
        "    [4, 1/2, 1/4, 1/3, 6, 1, 2, 2],\n",
        "    [2, 1/2, 1/3, 1/2, 7, 1/2, 1, 1/6],\n",
        "    [2, 1/3, 1/5, 1/2, 8, 1/2, 6, 1]\n",
        "])\n",
        "\n",
        "# Store matrices in a dictionary for easy access\n",
        "lB = [B1, B2, B3, B4, B5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MUZ3XaxAEyeG",
        "outputId": "87ae9295-53c0-4b54-f29b-621d512435ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Aggregated criteria matrix:\n",
            "   C1 C2 C3 C4 C5 \n",
            "C1 1.0000 3.7798 3.3019 4.8203 0.7937 \n",
            "C2 0.2646 1.0000 0.5429 0.6786 1.0000 \n",
            "C3 0.3029 1.8420 1.0000 1.1856 1.7100 \n",
            "C4 0.2075 1.4736 0.8434 1.0000 1.3050 \n",
            "C5 1.2599 1.0000 0.5848 0.7663 1.0000 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Solution:"
      ],
      "metadata": {
        "id": "AmUB3TcjFIe2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "weights = kappa(DM)\n",
        "aggregated_matrix = aggregated_preference_matrix(lB, weights)\n",
        "z_CI = kappa(aggregated_matrix)\n",
        "print(\"Final results z_CI:\")\n",
        "print_named_matrix_or_vector(z_CI, bNames)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-8zXvbhoFgK_",
        "outputId": "c46e86c9-c962-4ee0-9efd-e637aa24a6ff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final results z_CI:\n",
            "AT1: 0.0457\n",
            "AT2: 0.0564\n",
            "AT3: 0.3656\n",
            "AT4: 0.1828\n",
            "AT5: 0.0630\n",
            "AT6: 0.0914\n",
            "AT7: 0.1219\n",
            "AT8: 0.0731\n"
          ]
        }
      ]
    }
  ]
}